### Comparing Grad-Cam explanations with human explanations 

This repository supports the paper _"Breaking out of the interpretability asylum using social sciences and coffee plates as battering ram."_. The code can be found in the file **code.ipynb** and images used are in the compressed file **images/data_2.zip**.

GradCam produces visual explanations by highlighting areas central to the decision making. Read more about GradCam in the paper _"Grad-cam: Visual explanations from deep networks via gradient-based localization"_ written by Selvaju et al. The Grad-CAM implementation is based on this paper.

For machine learning part of the work we used the framework by [Fast.ai](fast.ai). 
