### Applying Human Explanation Theories to Machine Learning.

This repository supports the paper _‘How Should AI Explain That to You?’_. The code can be found in the file **code.ipynb** and images used are in the compressed file **images/data_2.zip**. The file **code/gradcam.py** contains the code to create the Grad-CAM images.

GradCam produces visual explanations by highlighting areas central to the decision making. Read more about GradCam in the paper _"Grad-cam: Visual explanations from deep networks via gradient-based localization"_ written by Selvaju et al. The Grad-CAM implementation is based on the Grad-CAM implementation in [Fast.ai](fast.ai). For machine learning part of the work we used the framework by [Fast.ai](fast.ai). 

### For double blind review
To anonymise the site, it is moved to an anonymous repository. This server is quite rudimentary and cannot render Jupyter Notebook so the central part of the file code.ipynb is replaced by four images (below). (Please excuse the slow server that needs patience and cannot show images embedded in markdown).
[Codepart1](code1.png),
[Codepart2](code2.png),
[Codepart3](code2.png),
[Codepart4](code2.png)
